{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Necessary Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Ancillary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Separate the 'id' column\n",
    "x_train_id = train_df.iloc[:, 0]  # First column as 'id'\n",
    "x_train_features = train_df.iloc[:, 1:-6]  # All columns except the first and the last 6 columns\n",
    "\n",
    "x_test_id = test_df.iloc[:, 0]  # First column as 'id'\n",
    "x_test_features = test_df.iloc[:, 1:]  # All columns except the first\n",
    "\n",
    "min_train = x_train_features.min()\n",
    "max_train = x_train_features.max()\n",
    "x_train_norm = (x_train_features - min_train) / (max_train - min_train)\n",
    "\n",
    "min_test = x_test_features.min()\n",
    "max_test = x_test_features.max()\n",
    "x_test_norm = (x_test_features - min_test) / (max_test - min_test)\n",
    "\n",
    "x_train = pd.concat([x_train_id, x_train_norm], axis=1)\n",
    "x_test = pd.concat([x_test_id, x_test_norm], axis=1)\n",
    "\n",
    "y_train = train_df.iloc[:, -6:]\n",
    "y_label = y_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load Pretrained ViT Model\n",
    "model_name = \"facebook/dinov2-giant\"\n",
    "feature_extractor = AutoImageProcessor.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Features Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from an image\n",
    "def extract_dino_features(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    inputs = feature_extractor(images=image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Obtain the CLS token\n",
    "    features = outputs.last_hidden_state[:, 0].cpu().numpy()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Features From Train Images Using ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the image folder\n",
    "train_image_folder = 'data/train_images'  # Update the path to your image folder\n",
    "\n",
    "# Extract features for all images and store them in a dictionary with IDs\n",
    "train_image_features_dict = {}\n",
    "for image_file in os.listdir(train_image_folder):\n",
    "    image_id = os.path.splitext(image_file)[0]  # image file name is the ID\n",
    "    image_path = os.path.join(train_image_folder, image_file)\n",
    "    features = extract_dino_features(image_path)\n",
    "    train_image_features_dict[image_id] = features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Features From Test Images Using ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the image folder\n",
    "test_image_folder = 'data/test_images'  # Update the path to your image folder\n",
    "\n",
    "# Extract features for all images and store them in a dictionary with IDs\n",
    "test_image_features_dict = {}\n",
    "for image_file in os.listdir(test_image_folder):\n",
    "    image_id = os.path.splitext(image_file)[0]  # image file name is the ID\n",
    "    image_path = os.path.join(test_image_folder, image_file)\n",
    "    features = extract_dino_features(image_path)\n",
    "    test_image_features_dict[image_id] = features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined Extracted Features with Ancillary Data for Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare tensors for combined features and labels\n",
    "train_combined_features_list = []\n",
    "\n",
    "for _, row in x_train.iterrows():\n",
    "    image_id = str(int(row['id']))  # Ensure the ID is in string format if necessary\n",
    "    if image_id in train_image_features_dict:\n",
    "        image_features = train_image_features_dict[image_id].squeeze()\n",
    "        ancillary_features = row.drop(labels=['id']).values\n",
    "        combined_features = np.concatenate((image_features, ancillary_features), axis=0)\n",
    "        train_combined_features_list.append(combined_features)\n",
    "\n",
    "train_combined_features_array = np.array(train_combined_features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined Extracted Features with Ancillary Data for Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare tensors for combined features and labels\n",
    "test_combined_features_list = []\n",
    "test_ids = []  # List to store IDs\n",
    "\n",
    "for _, row in x_test.iterrows():\n",
    "    image_id = str(int(row['id']))  # Ensure the ID is in string format if necessary\n",
    "    if image_id in test_image_features_dict:\n",
    "        image_features = test_image_features_dict[image_id].squeeze()\n",
    "        ancillary_features = row.drop(labels=['id']).values\n",
    "        combined_features = np.concatenate((image_features, ancillary_features), axis=0)\n",
    "        test_combined_features_list.append(combined_features)\n",
    "        test_ids.append(image_id)\n",
    "\n",
    "test_combined_features_array = np.array(test_combined_features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the Combined Data For Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transformation of targets\n",
    "y_train_log = np.log10(y_train)\n",
    "\n",
    "# Remove outliers (values beyond three standard deviations)\n",
    "# mean = y_train_log.mean()\n",
    "# std = y_train_log.std()\n",
    "# mask = (y_train_log >= mean - 3*std) & (y_train_log <= mean + 3*std)\n",
    "# y_train_log = y_train_log[mask.all(axis=1)]\n",
    "# # update the data by removing some outliers\n",
    "# x_combined_train = train_combined_features_array[mask.all(axis=1)]\n",
    "\n",
    "# Normalization targets\n",
    "min_train = y_train_log.min()\n",
    "max_train = y_train_log.max()\n",
    "y_train_norm = (y_train_log - min_train) / (max_train - min_train)\n",
    "\n",
    "# Split the training data into training and validation sets (20%)\n",
    "x_train_split, x_val, y_train_split, y_val = train_test_split(train_combined_features_array, y_train_norm, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train = x_train_split\n",
    "y_train = y_train_split.values\n",
    "x_val = x_val\n",
    "y_val = y_val.values\n",
    "x_test = test_combined_features_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "model = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse',\n",
    "    eta=0.05,\n",
    "    max_depth=8,\n",
    "    n_estimators=1000,\n",
    "    tree_method='hist',\n",
    "    device=\"cuda\",\n",
    "    early_stopping_rounds = 10,\n",
    "    reg_alpha=0.2,\n",
    "    reg_lambda=1.2\n",
    ")\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(x_train, y_train, eval_set=[(x_val, y_val)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce Predictions for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Convert predictions to original scale\n",
    "# predictions = predictions.cpu().numpy()\n",
    "max_train = np.array(max_train).reshape(1, 6)\n",
    "min_train = np.array(min_train).reshape(1, 6)\n",
    "predictions_original_scale = (predictions * (max_train - min_train)) + min_train\n",
    "\n",
    "predictions_original_scale = 10 ** predictions_original_scale\n",
    "\n",
    "# Convert predictions to DataFrame\n",
    "predictions_df = pd.DataFrame(predictions_original_scale, columns=y_label)\n",
    "\n",
    "\n",
    "predictions_df.insert(0, 'id', test_ids)  # Insert the IDs as the first column\n",
    "# Save predictions to CSV\n",
    "predictions_df.to_csv('cs480-kaggle.csv', index=False)\n",
    "\n",
    "print(\"Predictions have been saved to 'cs480-kaggle.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
